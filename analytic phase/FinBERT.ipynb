{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPZgjCooEZMh+9AzTpjr7LN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uqtpfCh3M9qR"},"outputs":[],"source":["import pandas as pd\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from torch.nn.functional import softmax\n","from tqdm import tqdm\n","\n","# === CONFIG ===\n","PARQUET_INPUT = \"financial_news.parquet\"     # <- your input file\n","TEXT_COLUMN = \"headline\"                     # <- change this if needed\n","OUTPUT_FILE = \"financial_news_with_sentiment.parquet\"\n","BATCH_SIZE = 32\n","\n","# === Load FinBERT ===\n","print(\"Loading FinBERT model...\")\n","tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","# === Load dataset ===\n","print(\"Loading data...\")\n","df = pd.read_parquet(PARQUET_INPUT)\n","texts = df[TEXT_COLUMN].astype(str).tolist()\n","\n","# === Define batching function ===\n","def batch_sentiment_analysis(texts, batch_size=32):\n","    sentiments = []\n","    confidences = []\n","\n","    for i in tqdm(range(0, len(texts), batch_size)):\n","        batch = texts[i:i+batch_size]\n","        encoded = tokenizer(batch, return_tensors='pt', padding=True, truncation=True)\n","\n","        input_ids = encoded['input_ids'].to(device)\n","        attention_mask = encoded['attention_mask'].to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            probs = softmax(outputs.logits, dim=1)\n","\n","        batch_sentiments = torch.argmax(probs, dim=1).tolist()\n","        batch_confidences = torch.max(probs, dim=1).values.tolist()\n","\n","        label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n","        sentiments.extend([label_map[s] for s in batch_sentiments])\n","        confidences.extend(batch_confidences)\n","\n","    return sentiments, confidences\n","\n","# === Run analysis ===\n","print(\"Analyzing sentiment...\")\n","sentiments, confidences = batch_sentiment_analysis(texts, batch_size=BATCH_SIZE)\n","\n","# === Save output ===\n","df[\"sentiment\"] = sentiments\n","df[\"confidence\"] = confidences\n","df.to_parquet(OUTPUT_FILE, index=False)\n","\n","print(f\"âœ… Sentiment analysis complete! Output saved to: {OUTPUT_FILE}\")\n"]}]}